{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c587be1-ca67-4b8c-b06c-c2b4b2c16d13",
   "metadata": {},
   "source": [
    "# CLIMATE DATA CHALLENGE 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed85cd-a00c-4ade-9106-020f602f1449",
   "metadata": {},
   "source": [
    "## Understanding Drivers of Uncertainty in Future Loss Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aba02-2308-4c2b-8762-967d252630f9",
   "metadata": {},
   "source": [
    "### Exposure scenario, sensitivity to:\n",
    "\n",
    "- Popultation increases\n",
    "- locality\n",
    "- building type\n",
    "- cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db9a54-ebbd-4c14-a46d-2c3c7bd7e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c5c62-2062-48c7-942f-f11ee3a17e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ascend\n",
    "from ascend import shape\n",
    "\n",
    "import datetime\n",
    "\n",
    "import iris\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc79383-5644-4001-a962-b3c8620208e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data filenames and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c7c8a-5732-41e9-97c2-44fb715e7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/net/home/h04/jmendes/ClimateDataChallenge/Met-Office-Climate-Data-Challenge-May-2022/data\"\n",
    "fexposure = \"UKMO_HACKATHON_EXPOSURE\"\n",
    "lst_countries = [\"United Kingdom\"]\n",
    "\n",
    "ssp_datadir = \"/data/users/ldawkins/UKCR/DataForPaper/UKSSPs\"\n",
    "ssp1_pop = \"population_SSP1_12km.nc\"\n",
    "ssp5_pop = \"population_SSP5_12km.nc\"\n",
    "ssp1_urb = \"urbanisation_SSP1_12km.nc\"\n",
    "ssp5_urb = \"urbanisation_SSP5_12km.nc\"\n",
    "\n",
    "ssps = [\"1\", \"5\"]\n",
    "sensitiv = [\"pop\", \"urb\", \"urbpop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974c458-a7bb-47fe-992e-05550921318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15b641-4354-4030-8d1b-db7dc2f8d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(datadir, fname, country=\"all\"):\n",
    "    '''\n",
    "    Read files from input directory.\n",
    "    \n",
    "    Args:\n",
    "        datadir (str): Path to input data dir\n",
    "        fname (str): Name of CSV file to load\n",
    "        country (list (str)): Country names to be selected.\n",
    "                              Default is to load all countries.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas dataframe of input data with 15-17 columns.\n",
    "    '''\n",
    "\n",
    "    # define filename\n",
    "    file = f\"{datadir}/{fname}.csv\"\n",
    "    \n",
    "#    # read file as dataframe and return\n",
    "#    return pd.read_csv(file, header = 1, names = columns)\n",
    "    # Make a one column dataframe with each row being a line in the CSV file\n",
    "    # original file is latin1 encoded\n",
    "    df = pd.read_fwf(file, header=None, encoding='latin1')\n",
    "    # split each row on commas and expand the dataframe\n",
    "    dfmod = df[0].str.split(',', expand=True)\n",
    "    if country == \"all\":\n",
    "        return dfmod\n",
    "    else:\n",
    "        return dfmod.loc[dfmod.iloc[:,7].isin(country)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1cbf3-ecf0-494f-857a-9de37c9491da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(cube):\n",
    "    '''\n",
    "    Convert cube's time coordinate onto decade.\n",
    "    \n",
    "    Args:\n",
    "        cube(iris cube): Input SSP cube.\n",
    "                         time units are 'hours since 1970-01-01 00:00:00'\n",
    "                         in Gregorian calendar.\n",
    "    \n",
    "    Returns:\n",
    "        List of decades (datetime year format)\n",
    "    '''\n",
    "\n",
    "\n",
    "    decades = []\n",
    "    for t in cube.coord(\"time\"):\n",
    "        decades.append(datetime.datetime.fromtimestamp(int(t.points)*3600).year)\n",
    "    \n",
    "    return decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d0450-ba40-4d6b-8ace-b998d9ce9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_replacecosts(datadir, data):\n",
    "    '''\n",
    "    Read replacement costs scenarios and original exposure data,\n",
    "    update exposure and save as CSV file, for each SSP-sensitivity.\n",
    "    \n",
    "    Args:\n",
    "        datadir (str): Path to input data dir\n",
    "        data (pandas DataFrame): Original exposure dataframe.\n",
    "    '''\n",
    "    \n",
    "    # run through each SSP and sensitivity and replace costs\n",
    "    for ssp in ssps:\n",
    "        for sens in sensitiv:\n",
    "            file = f\"{datadir}/SSP{ssp}_new_replacement_costs_{sens}.npy\"\n",
    "            new_cost = np.load(file)\n",
    "            data[\"BuildingsReplacement\"] = new_cost\n",
    "            data.iloc[:,:15].to_csv(f\"{datadir}/{fexposure}_UK_SSP{ssp}_{sens}.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379bc02-6cd3-413f-90de-f3cafedad97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_stories(datadir, data):\n",
    "    '''\n",
    "    Read new stories scenarios (based on increase of at least 20% \n",
    "    in population) and original exposure data;\n",
    "    update exposure and save as CSV file.\n",
    "    \n",
    "    Args:\n",
    "        datadir (str): Path to input data dir\n",
    "        data (pandas DataFrame): Original exposure dataframe.\n",
    "    '''\n",
    "    \n",
    "    # run through each SSP (20% population increase scenario)\n",
    "    for ssp in ssps:\n",
    "        file = f\"{datadir}/SSP{ssp}_updated_residential_stories.npy\"\n",
    "        new_stories = np.load(file)\n",
    "        data[\"Stories\"] = new_stories\n",
    "        data.iloc[:,:15].to_csv(f\"{datadir}/{fexposure}_UK_SSP{ssp}_stories.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36856bf8-fe43-4f18-a858-93f6a20859c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f75be5-771d-4167-ba9e-78211ca65384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse exposure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a053d-0c19-4b74-bf8f-4c80cca7a23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = read_file(datadir, fexposure, country=lst_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fcff5-866a-4aee-9563-25c145585175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6824035-bf6e-4ec4-b8a2-974074e60e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names\n",
    "cols_dict = {\n",
    "    list(data)[0]: \"LocationSID\",\n",
    "    list(data)[1]: \"LocationName\",\n",
    "    list(data)[2]: \"BuildingsReplacement\",\n",
    "    list(data)[3]: \"ContentsReplacement\",\n",
    "    list(data)[4]: \"BusinessInteruptionReplacement\",\n",
    "    list(data)[5]: \"CurrencyCode\",\n",
    "    list(data)[6]: \"Territory\",\n",
    "    list(data)[7]: \"CountryName\",\n",
    "    list(data)[8]: \"PostalCode\",\n",
    "    list(data)[9]: \"PostalName\",\n",
    "    list(data)[10]: \"Latitude\",\n",
    "    list(data)[11]: \"Longitude\",\n",
    "    list(data)[12]: \"Stories\",\n",
    "    list(data)[13]: \"Occupancy\",\n",
    "    list(data)[14]: \"Construction\"\n",
    "}\n",
    "\n",
    "data.rename(columns=cols_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec25db-8eb2-4bc5-974b-5b86f1eabf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save country data with assign column names\n",
    "data.iloc[:,:15].to_csv(f\"{datadir}/{fexposure}_UK.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912500e-a1fa-4064-9d8d-affeced4cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of fields:\n",
    "print(\"Stories: \", data[\"Stories\"].unique())\n",
    "print(\"Occupancy: \", data[\"Occupancy\"].unique())\n",
    "print(\"Construction: \", data[\"Construction\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca4178-b78b-452f-904e-8a43415381b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update replacement costs in the original datafile with new scenarios:\n",
    "# combinations of: SSP1, SSP5; population, urbanisation, population-urbanisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28e5af-085e-4182-aeb8-bc8551bd952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace original dataset with new scenarios\n",
    "new_replacecosts(datadir, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0e8f2-6ef8-4ca0-a90c-6cadb7ca41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update stories in the original datafile with new scenario:\n",
    "# >20% increase in population leading to more stories (SSP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eff019-bbbe-4eaa-b5f9-66239d6c8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stories(datadir, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba88a5-0efe-4388-be40-f46d6b7b3eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6d365-a13b-4ebf-897e-d27a152f455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra scripts to read shape and netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cccf30-0e42-4177-bd9c-786252be4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada130c6-c8b2-4acf-90d2-6bd118cbf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = shape.load_shp(f\"{datadir}/Control_scenario_UK.shp\")\n",
    "#shape.inspect_shp_info(f\"{datadir}/Control_scenario_UK.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b8c85-9e98-4c0f-8dce-da62197d16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape.show(shp, bounds=[-20, 40, 35, 72], scale=\"50m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee06f8-d998-42da-ad49-6ab0c7ae14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rivers test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5710ab1-0118-4b18-bd72-80d40ee37a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_dir = \"/project/cst/ascend/natural_earth/50m_physical\"\n",
    "river_shapefile = f\"{ne_dir}/ne_50m_rivers_lake_centerlines.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf9c27-f515-49ad-9612-83de275793ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rivers = shape.load_shp(river_shapefile)\n",
    "#rivers.show(bounds=[-4., 3., 50., 55.], scale='10m')\n",
    "\n",
    "#rivers_select = [\n",
    "#    \"Ness\",\n",
    "#    \"Oich\",\n",
    "#    \"Trent\",\n",
    "#    \"Severn\",\n",
    "#    \"Caledonian Canal\",\n",
    "#    \"Thames\",\n",
    "#    \"Annalee\",\n",
    "#    \"Great Ouse\",\n",
    "#    \"Tweed\",\n",
    "#    \"Wye\",\n",
    "#    \"Swale\",\n",
    "#    \"Bann\",\n",
    "#    \"Tay\",\n",
    "#    \"Blackwater\"\n",
    "#]\n",
    "#\n",
    "#for river in rivers_select:\n",
    "#    river_shape = shape.load_shp(river_shapefile, name=river)[0]\n",
    "#    river_shape.show(bounds=[-4., 3., 50., 55.], scale='50m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a6519-217d-4d4a-8127-97e25a9a425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thames_shape = shape.load_shp(river_shapefile, name='Thames')[0] #select first shape from the list\n",
    "thames_shape.show(bounds=[-4., 3., 50., 55.], scale='50m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03c1f7-ca78-4ac4-86aa-9dcdd147e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797a899-72c3-4730-867f-4a8ec92e27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec382e3d-d0db-44ad-91ab-1c20518cbf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP1, population\n",
    "pop1 = iris.load_cube(f\"{ssp_datadir}/{ssp1_pop}\")\n",
    "pop1_decades = convert_time(pop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8426e1-f240-4836-83de-dac0f7a0cd9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2d945-fd58-47fb-8ee9-e6bea03e5009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec = len(pop1_decades)\n",
    "i = 0\n",
    "for time in range(0, dec):  # for each aggregated time\n",
    "    plt.subplot(2,5,i+1)\n",
    "    qplt.contour(pop1[i])\n",
    "    plt.title(pop1_decades[i])\n",
    "    plt.gca().coastlines()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4748d-739d-438e-a6c4-0d1b3716a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP5, population\n",
    "pop5 = iris.load_cube(f\"{ssp_datadir}/{ssp5_pop}\")\n",
    "pop5_decades = convert_time(pop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28d2a1-dccc-4cba-b35e-5dec5a902f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP1, urbanisation\n",
    "urb1 = iris.load_cube(f\"{ssp_datadir}/{ssp1_urb}\")\n",
    "urb1_decades = convert_time(urb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf930d6-c358-4da8-b824-50f8aea19cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSP5, urbanisation\n",
    "urb5 = iris.load_cube(f\"{ssp_datadir}/{ssp5_urb}\")\n",
    "urb5_decades = convert_time(urb5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e13096-b4ad-4d1c-9c8f-fb19ccbb96f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1f852-7a0e-4b21-ab69-272084ed2fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-current",
   "language": "python",
   "name": "default-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
